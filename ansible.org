* ansible
#+BEGIN_SRC 
 $ansible <system>
-i <inventory file>
-m <module>
-u <username>
-k <passowr prompt>
-v <verbose -vv debug level 2 / -vvv debug level 3)

#+END_SRC

- Change Management

- Provisioning
Transiton from one state to another. Pepare system to be ready
- Automation
Sequence of steps to perform automated
- Orchestration
Coordinates automation between systems

- Why?
No agents
no database
No residual software
No complex upgrades (no external dependencies)

Easy to implement easy to progarm inherently secure. ssh very extensible



Inventory(maps hosts)
||
PlayBook => Ansible Config(configuration sets, ansible parameters) => Python => SSH =>......servers.....
||
Modules (define actions)

- Variables
  - Host Variables
    - User variables, inventory per host or group
  - Facts
    - Use data gathered from remote managed host
  - Dynamic variables
    - use data gathered by tasks or created by runtime

- Control server =(package)=> Remote Servers
- Remote server =(results.json)=> Control Server


* ansible-playbooks

** Inventory, Config and Parameters
Behavioral Inventory Parameters, Ansible.cfg
| ansible_ssh_user             | remote_user      |
| ansible_ssh_port             | remote_port      |
| ansible_ssh_private_key_file | private_key_file |
| ansible_shell_type           | executable       |
| ansible_ssh_connection       |                  |
| ansible_python_interpreter   |                  |

#+BEGIN_SRC 
[web]
web[1:20].example.com
#+END_SRC

Dynameic inventory scripts:
https://github.com/ansible/ansible/tree/release1.5.0/plugins/inventory

add_host and group_by

** Tasks
#+BEGIN_SRC 
 - hosts: all
   user: root
   sudo: no
   vars:
     aaa: bbb
   tasks:
     - ...
   handlers:
     - ...

#+END_SRC
** Includes

#+BEGIN_SRC 
 tasks:
   - include: db.yml
 handlers:
   - include: db.yml user=timmy

#+END_SRC 
** Handlers
#+BEGIN_SRC 
 handlers:
   - name: start apache2
     action: service name=apache2 state=started

 tasks:
   - name: install apache
     action: apt pkg=apache2 state=latest
     notify:
       - start apache2

#+END_SRC 
** Vars
#+BEGIN_SRC 
 - host: lol
   vars_files:
     - vars.yml
   vars:
     project_root: /etc/xyz
   tasks:
     - name: Create the SSH directory.
       file: state=directory path=${project_root}/home/.ssh/
       only_if: "$vm == 0"

#+END_SRC 
** Roles
#+BEGIN_SRC 
 - host: xyz
   roles:
     - db
     - { role:ruby, sudo_user:$user }
     - web

 # Uses:
 # roles/db/tasks/*.yml
 # roles/db/handlers/*.yml

#+END_SRC 
** Roles dir structure
#+BEGIN_SRC 

roles/
  common/
    tasks/
    handlers/
    files/              # 'copy' will refer to this
    templates/          # 'template' will refer to this
    meta/               # Role dependencies here
    vars/
    defaults/main.yml

#+END_SRC

** Task: Failures

#+BEGIN_SRC 
 - name: my task
   command: ...
   register: result
   failed_when: "'FAILED' in result.stderr"

   ignore_errors: yes

   changed_when: "result.rc != 2"

#+END_SRC
 
** Env vars

#+BEGIN_SRC 
 vars:
   local_home: ""

#+END_SRC

** Ansible commands

*** Playbooks
#+BEGIN_SRC 
 ansible-playbook <YAML># Run on all hosts defined
 ansible-playbook <YAML> -f 10# Run 10 hosts parallel
 ansible-playbook <YAML> --verbose# Verbose on successful tasks
 ansible-playbook <YAML> -C# Test run
 ansible-playbook <YAML> -C -D# Dry run
 ansible-playbook <YAML> -l <host># Run on single host

#+END_SRC

 # Run Infos
#+BEGIN_SRC 
 ansible-playbook <YAML> --list-hosts
 ansible-playbook <YAML> --list-tasks

#+END_SRC
 # Syntax Check
 ~ansible-playbook --syntax-check <YAML>~

*** Remote Execution

~ansible all -m ping~

 # Execute arbitrary commands
 ~ansible <hostgroup> -a <command>~
 ~ansible all -a "ifconfig -a"\~

*** Debugging

 List facts and state of a host

 ~ansible <host> -m setup~
 ~ansible <host> -m setup -a 'filter=ansible_eth*'\~

** Common Modules
*** Aptitude
#+BEGIN_SRC 

 - apt_key: id=AC40B2F7 url="http://..."
     state=present

 - apt: pkg=nodejs state=present
     state=present # absent | latest
     update_cache=yes
     force=no
 apt: deb=https://packages.erlang-solutions.com/erlang-solutions_1.0_all.deb
 - apt_repository: repo='deb https://... raring main'
     state=present
#+END_SRC
*** file
#+BEGIN_SRC 

 - file:
     state=directory # file | link | hard | touch | absent
     path=/etc/dir
     owner=bin
     group=wheel
     mode=0644
     recurse=yes  # mkdir -p
     force=yes    # ln -nfs

 - copy:
     src=/app/config/nginx.conf
     dest=/etc/nginx/nginx.conf

 - template:
     src=config/redis.j2
     dest=/etc/redis.conf
#+END_SRC
*** git
#+BEGIN_SRC 

 - git: repo=git://github.com/
     dest=/srv/checkout
     version=master
     depth=10
     bare=yes
#+END_SRC
*** user
#+BEGIN_SRC 

 - user: state=present name=git
     system=yes
     shell=/bin/sh
     comment="Git Version Control"
#+END_SRC
*** service

 ~- service: name=nginx state=started [enabled=yes]~
*** shell

 ~- shell: apt-get install nginx -y~
 ~- script: /x/y/script.sh~
*** local_action
#+BEGIN_SRC 

 - name: do something locally
   local_action: shell echo hello

#+END_SRC
*** debug
#+BEGIN_SRC 

 - debug:
     msg: "Hello "

#+END_SRC
*** register
#+BEGIN_SRC 
- name: "list the latest {{project.artifact_type}} from {{project.project_id}} from s3 bucket"
  shell: "aws s3 ls --recursive s3://{{s3_bucket_name}}/{{project.project_id}} | sort | tail -n 1 | awk -F \" \" '{print $4}'"
  register: resp
- debug: var=resp
#+END_SRC
*** set_fact
#+BEGIN_SRC 
- set_fact: project="{{item}}"
# - name: Starts from scratch {{base_dir}}docker/{{project.project_id}}
#   file: path={{base_dir}}docker/{{project.project_id}} state=directory
- include: download_tar.yaml
  when: project.artifact_type=='tar.gz'
#+END_SRC
** Ansible playbook some parameters

**** Inventory
ansible-playbook -i hosts main.yaml

**** Host key checking disable

~ansible-playbook -i hosts -e 'host_key_checking=False' main.yaml~

**** Extra params

#+BEGIN_SRC 
ansible-playbook -i hosts -e "host_key_checking=False" main.yaml --extra-vars "deploy_host=${envname}"
#+END_SRC

...and receive it like this in playbook:

#+BEGIN_SRC 
hosts: "{{ deploy_host | default('dev') }}"
#+END_SRC

*** ansible.cfg to configure params
#+BEGIN_SRC 
[defaults]
hostfile = hosts
ansible_connection=local
Add a comment to this line
vault_password_file = vault_pass.py
host_key_checking = False

#+END_SRC

http://docs.ansible.com/ansible/latest/intro_configuration.html

*** copy remote src
#+BEGIN_SRC 
    - name: Unzip WAR file
      unarchive:
        src: "{{ playbook_dir }}/target/{{ warName }}"
        dest: /usr/share/tomcat/webapps/{{project_id}}/ 
        mode: 0755
        remote_src: yes
        owner: tomcat
        group: tomcat
      become: true
#+END_SRC

** Docker, Springboot, Postgresql, Nginx kickstart playbook

#+BEGIN_SRC 
---
- hosts: localhost
  connection: local
  become: true
  gather_facts: true
  vars_files:
    - settings.yaml
  vars:
    proj_name: "devopscicd"
    nginx_host: "devopscicd.xyz.com"
    nginx_port: 80
    dashboard_ui_port: 8092
    dashboard_api_port: 8091
    postgresql_db_port: 5432
  tasks:
  - name: Create the network
    docker_network:
      name: dodashb_network

  - name: build ./nginx/ image  
    docker_image: 
      path: ./dev/docker/webserv/
      name: ddb_webserv

  - name: build ./postgresql/ image  
    docker_image: 
      path: ./dev/docker/postgresql/
      name: postgresql_db

  - name: build ./nginx/ image  
    docker_image: 
      path: ./dev/docker/nginx/
      name: ddb_nginx

  - name: build ./dashboard-api/ image  
    docker_image: 
      path: ./dev/docker/dashboard-api/
      name: dashboard-api

  - name: start postresql_db container
    docker_container:
      name: postgresql_db
      image: postgresql_db
      volumes:
        - ./postgresql/db:/var/lib/postgresql/data
      ports:
        - "5432:5432"
      env:
        DEBUG: "false"
        POSTGRES_USER: "sa"
        POSTGRES_PASS: "password"
        POSTGRES_DB: "devopscicd_db"
      state: "started"
      restart: "yes"
      networks:
        - name: dodashb_network

  - name: start dashboard-api container
    docker_container:
      name: dashboard-api
      image: dashboard-api
      volumes:
        - ./dashboard-api/logs:/opt/logs
        - ./dashboard-api/app:/opt/target
      ports:
        - "8091:8091"
      links:
        - postgresql_db
      networks:
        - name: dodashb_network
      state: "started"
      restart: "yes"

  - name: run dashboard_ui container
    docker_container:
      name: dashboard_ui
      image: ddb_webserv
      volumes:
        - ./dashboard/app:/var/www
      ports:
        - "8092 : 80"
      networks:
        - name: dodashb_network
      state: "started"
      restart: "yes"

  - name: start nginx container
    docker_container:
      name: ddb_nginx_webserv
      image: ddb_nginx
      volumes:
        - ./ddb_nginx/app:/var/www
      ports:
        - "80 : 80"
      networks:
        - name: dodashb_network
      state: "started"
      restart: "yes"

#+END_SRC


** Probe host 

#+BEGIN_SRC 
---
- name: Probe a system until it is up
  hosts: localhost
  connection: local
  gather_facts: no
  vars:
    probe_host: "{{ probe_host | default('dev.devakthk.ddns.net') }}"
    probe_port: "{{ probe_port | default('80') }}"
    probe_delay: "{{ probe_delay | default('0') }}"
    probe_timeout: "{{ probe_timeout | default('180') }}"
  tasks:
  - name: Message
    debug: 
      msg: >
        Probing {{ probe_host }}:{{ probe_port }} with delay={{ probe_delay }}s
        and timeout={{ probe_timeout}}s
  - name: Waiting for host to respond...
    local_action: >
      wait_for host={{ probe_host }}
      port={{ probe_port }}
      delay={{ probe_delay }}
      timeout={{ probe_timeout }}

#+END_SRC

** List s3 bucket latest

#+BEGIN_SRC 
- hosts: localhost
  connection: local
  vars:
    s3_bucket_name: mybucket-repo
    project_id: auth-api
  tasks:
    - name: "list all jars in s3 bucket"
      shell: "aws s3 ls --recursive s3://{{s3_bucket_name}}/{{project_id}} | grep '.*\\.jar$' | awk -F \" \" '{print $4}'"
      register: resp
    - debug: var=resp

    - name: "list the latest jar in s3 bucket"
      shell: "aws s3 ls s3://{{s3_bucket_name}}/{{project_id}}/ --recursive | sort | tail -n 1 | awk -F \" \" '{print $4}'"
      register: resp
    - debug: var=resp
#+END_SRC


** Ensure ../tomcat/bin/setenv.sh file exists if not - create it and ensure it sets environment variables

#+BEGIN_SRC 
    - stat: path=/usr/share/tomcat/bin/setenv.sh
      register: setenv_status
      become: true

    - name: create blank 'setenv'
      file:
        path: "/usr/share/tomcat/bin/setenv.sh"
        state: touch
        owner: tomcat
        group: tomcat
        mode: 0755
      when: setenv_status.stat.exists is defined and not setenv_status.stat.exists
      become: true

    - name: Ensures /usr/share/tomcat/bin/setenv.sh exists
      file:
        path: "/usr/share/tomcat/bin/setenv.sh"
        state: file
        mode: 0755
        owner: tomcat
        group: tomcat
      become: true
      
    - name: Set the SPRING_PROFILES_ACTIVE in setenv.sh to keep it permanent
      lineinfile: "dest=/usr/share/tomcat/bin/setenv.sh line='export SPRING_PROFILES_ACTIVE=local' insertafter='EOF' state=present mode=0755"
      become: true
      
    - name: ensure SPRING_PROFILES_ACTIVE environment variable
      shell: "source /usr/share/tomcat/bin/setenv.sh && echo $SPRING_PROFILES_ACTIVE"
      become: true
      become_user: tomcat
      args:
        executable: "/bin/bash"
      register: spring_profiles_active_value
    
    - debug: var=spring_profiles_active_value
#+END_SRC

** Set bashrc for user

#+BEGIN_SRC 
    - name: Ensures /usr/share/tomcat/.bashrc exists
      file:
        path: "/usr/share/tomcat/.bashrc"
        state: file
        mode: 0644
        owner: tomcat
        group: tomcat
      become: true
      
    - name: Set the SPRING_PROFILES_ACTIVE in bashrc to keep it permanent
      lineinfile: "dest=/usr/share/tomcat/.bashrc line='export SPRING_PROFILES_ACTIVE=local' insertafter='EOF' state=present mode=0644"
      become: true
      
    - name: ensure SPRING_PROFILES_ACTIVE environment variable
      shell: "source /usr/share/tomcat/.bashrc && echo $SPRING_PROFILES_ACTIVE"
      become: true
      become_user: tomcat
      args:
        executable: "/bin/bash"
      register: spring_profiles_active_value
    
    - debug: var=spring_profiles_active_value

#+END_SRC

** Postgresql Setup the User, Database and use no_password_change on RDS

RDS gives following error on update to db, for this no_password_change parameter is required.

permission denied for relation pg_authid

#+BEGIN_SRC 
---
- name: Ensure python-psycopg2 is installed
  package:
    name: python-psycopg2
    state: present
  become: true

- name: ensure database is created
  postgresql_db:
    name: "{{app_dbname}}"
    login_host: "{{db_login_host}}"
    port: "{{db_login_port}}"
    login_password: "{{db_login_password}}"
    login_user: "{{db_login_user}}"

- debug:
    msg:  "login_host: {{db_login_host}} login_user: {{db_login_user}} port: {{db_login_port}} db: {{app_dbname}} name: {{app_dbuser}}"

# For RDS  : https://github.com/ansible/ansible/issues/8547
- name: ensure user has access to database
  #become: true
  #become_user: "{{db_login_user}}"
  postgresql_user: 
    login_host: "{{db_login_host}}"
    login_password: "{{db_login_password}}"
    login_user: "{{db_login_user}}"
    port: "{{db_login_port}}"
    db: "{{app_dbname}}"
    name: "{{app_dbuser}}"
    password: "{{app_dbpassword}}"
    no_password_changes: true
    state: present

- name: ensure user does not have unnecessary privilege
  postgresql_user: 
    login_host: "{{db_login_host}}"
    port: "{{db_login_port}}"
    login_password: "{{db_login_password}}"
    login_user: "{{db_login_user}}"
    # db: "{{app_dbname}}"
    name: "{{app_dbuser}}"
    # password: "{{app_dbpassword}}"
    no_password_changes: true
    role_attr_flags: "NOSUPERUSER,NOCREATEDB"

- name: ensure no other user can access the database
  postgresql_privs: 
    login_host: "{{db_login_host}}"
    port: "{{db_login_port}}"
    login_password: "{{db_login_password}}"
    login_user: "{{db_login_user}}"
    db: "{{app_dbname}}"
    role: PUBLIC
    type: database
    priv: ALL
    state: absent

# - debug:
#     msg: "app_dbschemas: {{item}}"
#   with_items:
#     - "{{app_dbschemas}}"

# - name: "setup the postgresql schemas"
#   postgresql_schema: 
#     login_host: "{{db_login_host}}"
#     login_password: "{{app_dbpassword}}"
#     login_user: "{{app_dbuser}}"
#     port: "{{db_login_port}}"
#     name: "{{item}}"
#     database: "{{app_dbname}}"
#     owner: "{{app_dbuser}}"
#     state: present
#   with_items:
#     - "{{app_dbschemas}}"
#+END_SRC

** simple ansible run script
#+BEGIN_SRC 
#!/bin/bash -xe
key_path=$1
tags=$2
playbook_name=$3
ansible-playbook -i hosts --private-key=${key_path} --tags=${tags} ${playbook_name}
#+END_SRC

Run like this:
~./run.sh ~/.ssh/cdhstack_admin.pem all main.yml~

** Ansible get the private ip and public ip
#+BEGIN_SRC 
---
- name: Basic
  become: true
  gather_facts: True
  hosts: all
  become: no
  become_user: "{{ansible_become_user}}"
  become_method: "{{ansible_become_method}}"
  tasks:
    - name: ping the host
      ping:
    - copy:
        content: "{{hostvars | to_nice_json}}"
        dest: "{{inventory_dir}}/hostvars.json"
      delegate_to: localhost
    - debug: 
        msg: "{{hostvars[groups['scm'][0]]['inventory_hostname']}}"
    - debug: 
        msg: "{{hostvars[groups['scm'][0]]['ansible_default_ipv4']['address']}}"
  tags:
    - ping
#+END_SRC

** Using AWS credentials from Environment variables

#+BEGIN_SRC 
  environment:
    AWS_ACCESS_KEY_ID: "{{ lookup('env', 'AWS_ACCESS_KEY_ID') }}"
    AWS_SECRET_ACCESS_KEY: "{{ lookup('env', 'AWS_SECRET_ACCESS_KEY') }}"
    AWS_DEFAULT_REGION: "{{AWS_DEFAULT_REGION}}" #"{{ lookup('env', 'AWS_DEFAULT_REGION') }}"
    AWS_DEFAULT_OUTPUT: "{{AWS_DEFAULT_OUTPUT}}" #"{{ lookup('env', 'AWS_DEFAULT_OUTPUT') }}"
  pre_tasks:
    - name: Ensure aws CLI is present
      pip: name=awscli state=present

    - name: "list the latest {{project_id}} {{artifact_type}} from s3 bucket"
      shell: "aws s3 ls --recursive s3://{{s3_bucket_name}}/{{project_id}}/builds | grep '.*\\.war$' | sort | tail -n 1 | awk -F \" \" '{print $4}'"
      register: resp
      when: artifact_type == 'war'
    - debug: var=resp

    - name: "download the latest war to user temp directory: {{base_dir}}tmp/{{project_id}}/"
      shell: "aws s3 cp s3://{{s3_bucket_name}}/{{resp.stdout}} {{base_dir}}tmp/app/{{project_id}}/"

#+END_SRC

** concatenate variables get dirname from path
#+BEGIN_SRC 
path: "{{(download_location+'/'+ item) | dirname}}"
#+END_SRC

** Create systemd service
#+BEGIN_SRC 
---
- name: "Check if use systemd"
  set_fact: use_system_d={{(ansible_distribution == 'Debian' and ansible_distribution_version | version_compare('8', '>=')) or (ansible_distribution in ['RedHat','CentOS'] and ansible_distribution_version | version_compare('7', '>=')) or (ansible_distribution == 'Ubuntu' and ansible_distribution_version | version_compare('15', '>=')) }}

- name: "Ensure systemd system directory is present (for Ubuntu)"
  file:
    path: "{{ sysd_user_services_folder }}"
    state: directory
    owner: root
    group: root

- name: "Create systemd service file"
  template:
    src: app.service.j2
    dest: "{{ sysd_script }}"
    mode: 0644
    owner: "{{ springboot_user }}"
    group: "{{ springboot_group }}"
  when: use_system_d

  notify:
    - "Restart application"
#+END_SRC

** Getting group hosts and list of ips in string concatenated via template
#+BEGIN_SRC 
stack_masters: "{{groups['hosts'][:1]}}"
stack_workers: "{{groups['hosts'][1:]}}"
ntp_server_host: "{{stack_masters[0]}}"

super_adm_passwd: "{{ ansible_fqdn | password_hash('sha512') | password_hash('sha512') }}"

SERVER_COUNT: "{{groups['hosts'] | length}}"
all_node_ips: |
  "{% for host in groups['hosts'] -%}
    {{ hostvars[host]['ansible_eth0']['ipv4']['address'] }}{% if not loop.last %}","{% endif %}
  {%- endfor %}"

#+END_SRC

** Variable from template and skipping the curent host
#+BEGIN_SRC 
stack_masters: "{{groups['hosts'][:1]}}"
stack_workers: "{{groups['hosts'][1:]}}"
ntp_server_host: "{{stack_masters[0]}}"

super_adm_passwd: "{{ ansible_fqdn | password_hash('sha512') | password_hash('sha512') }}"

SERVER_COUNT: "{{groups['hosts'] | length}}"
all_node_private_ips: |
  "{% for host in groups['hosts'] -%}
    {{ hostvars[host]['ansible_eth0']['ipv4']['address'] }}{% if not loop.last %}","{% endif %}
  {%- endfor %}"

all_hostnames: |
  "{% for host in groups['hosts'] -%}
    {{host}}{% if not loop.last %}","{% endif %}
  {%- endfor %}"
#+END_SRC

** don't re_download if already exist
#+BEGIN_SRC 
- name: check if the artifact exists
  stat: path=/tmp/{{ item.package }}
  register: package_exists

- name: "download {{item.name}}"
  get_url:
    url: "{{ item.url }}"
    dest: /tmp/{{ item.package }}
    mode: 0644
  when: package_exists.stat.exists == False or re_download == True

- name: unarchive 
  unarchive:
    remote_src: yes
    dest: "{{ install_base_dir }}/"
    src: /tmp/{{ item.package }}
  when: package_exists.stat.exists == False or re_download == True
#+END_SRC

** docker from tgz

install.yml
#+BEGIN_SRC 
---
- name: "ensure install base directoy"
  file:
    path: '{{item.home_dir}}'
    state: directory
    mode: 0755

- name: "download {{item.name}}"
  get_url:
    url: "{{ item.url }}"
    dest: /tmp/{{ item.package }}
    mode: 0644

- name: unarchive 
  unarchive:
    remote_src: yes
    dest: "{{ item.home_dir }}"
    src: /tmp/{{ item.package }}
    mode: 0755
    extra_opts: [--strip-components=1]
#+END_SRC
main.yml
#+BEGIN_SRC 
---
- name: install package
  include_tasks: install.yml
  with_items:
    - "{{docker_package}}"

- name: create docker service file
  template:
    src: "{{item}}.j2"
    dest: "/usr/lib/systemd/system/{{item}}"
    mode: 0755
  with_items:
    - docker.service

- name: enable the docker service
  service:
    name: docker
    enabled: yes

- name: start the docker service
  service:
    name: docker
    state: started

- name: include the users tasks
  include_tasks: users.yml

- name: start the docker service
  service:
    name: docker
    state: restarted
#+END_SRC

users.yml

#+BEGIN_SRC 
---
- name: "Ensure group {{item}} exists"
  group:
    name: "{{item}}"
    state: present
  with_items:
    - "{{service_accounts}}"

- name: "Ensure the user {{item}} with a bash shell, appending the group {{item}}"
  user:
    name: "{{item}}"
    shell: /bin/bash
    groups: "{{item}}"
    append: yes
  with_items:
    - "{{service_accounts}}"

- name: assign the current user to this group
  user:
    name: "{{ ansible_user }}"
    groups: "{{item}}"
    append: yes
  with_items:
    - "{{service_accounts}}"

#+END_SRC

docker.service.j2
#+BEGIN_SRC 
[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target

[Service]
Type=notify
# the default is not to use systemd for cgroups because the delegate issues still
# exists and systemd currently does not support the cgroup feature set required
# for containers run by docker
ExecStart=/usr/bin/dockerd
ExecReload=/bin/kill -s HUP $MAINPID
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
#TasksMax=infinity
TimeoutStartSec=0
# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes
# kill only the docker process, not all processes in the cgroup
KillMode=process
# restart the docker process if it exits prematurely
Restart=on-failure
StartLimitBurst=3
StartLimitInterval=60s

[Install]
WantedBy=multi-user.target
#+END_SRC
* Quick ref
 - Inventory and Config
   - features
     - Behavioral params
     - Groups
     - Group of groups
     - Assign Variables
     - Scaling multiple
     - Static/Dynamic
   - vars director structure
     #+BEGIN_SRC 
      dev 
       - group_vars 
         -all 
         -db 
         -webservers 
       - host_vars 
         -web1 
      inventory_dev
     #+END_SRC

   - variable file
     - start wiht ---
   - order of precedence
     - all
       - 
     - group<name>
     - host vars
   - imp ~ansible_python_interpreter=/usr/bin/python -~
   - configs
     - config order of prec
       - $ansible_config
       - ./ansible.cfg
       - ~/.ansible.cfg
       - /etc/ansible/ansible.cfg
       - 
     - configs are not merged
       - override by $ansible_<variable name>
     - defaults
       - forks default=*
       - host_key_checking default=true
       - log_path default=null
     - 
 - Modules
   - docs
     - ansible-doc -l
     - ansible-doc <name>
     - ansible-doc -s <name> //for play
   - copy
   - apt
   - yum
   - service
   - ansible web* -i inveontory setup
     - returns the facts of the system
 - host/group target patterns
   - OR grp*:grp*
   - NOT !group*
   - Wildcard web1 .ex.com
   - regex web[*-*]+
 - playbooks
   - declarations
     - top: hosts:, vars:, sudo:, sudo_user:, gather_facts:<no>
     - tasks:
       - name module:params
   - retry files for failed tasks
     - ansible-playbook x.yaml --limit @/home/vagrant/web_db.yaml.retry
   - Important modules
     - include: loadbalancer.yml
     - include_vars: xx.yaml
     - debug: msg="this is {{xx}} "
       - var=varname
     - vars_prompt
     - task>notify: handlers:
     - command: /ls/... register: result when: result|failed
     - template:
       - src: templates/xx.j*
       - dest=/etc/.... owner=httpd
