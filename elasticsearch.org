* elasticsearch
** How search works

- Web Crawler
- Inverted index
- Scoring
- Search

** inverted index

words -> frequency of occurance -> document

Different types of searches:
- Geo 
- Metaphonic (phonetic rhyme)

** Lucene

Just like Hadoop a nucleus of various tech

- Solr : search server
  - distributed indexing
  - load balancing
  - replication etc.
- Nutch: web crawling and index parsing
- Elasticsearch: distributed search and analytics engine


** Elasticsearch 

- Distributed
- High availability
- Restfull api
- Powerfull query dsl
- Schemaless : index data without any specific schema

Start with params:
./bin/elasticsearch -Ecluster.name=amitthk_cluster -Enode.name=node_one


*** Node
- Single server
- Performs indexing
- Allows search
- Has unique id and name

*** Cluster
- Collection of nodes
- Has unique name
- Nodes join cluster

*** Documents
- Basic unit of information to be indexed
- Expressed in JSON
- Resides in an index
- Assigned with a type

*** Types
- Logical partitioning of documents
- User defined symantic groupings
- Documents with "same fields" belong to one  type

*** Index
- Collection of similar documents
  - Documents are divided into multiple types (like catalogs, reports, video index etc.)
- Identified by name
- Any number of indices in a cluster
- Different indices for different logical grouping of data

Index can be split into multiple Shards. A shard can be replicated zero or more times.

By default an index in elasticsearch has 5 shards and 1 replica.

**** Shards
- Index on one node slow
- Search in parallel on multiple nodes
- Split the index accross multiple nodes in a cluster
- Every node will have a near subset of your index

**** Replicas
- Every shard will have a corresponding replica
- If node fails, replica can balance

http://localhost:9200/_cat/health?v&pretty

http://localhost:9200/_cat/nodes?v&pretty



** Install notes - elasticsearch logstash

*** elasticsearch

**** using yum

#+BEGIN_SRC 
sudo yum install java-1.8.0-openjdk.x86_64
wget https://download.elastic.co/elasticsearch/elasticsearch/elasticsearch-1.7.3.noarch.rpm
sudo rpm -ivh elasticsearch-1.7.3.noarch.rpm
sudo systemctl enable elasticsearch.service
#+END_SRC

~vi /etc/elasticsearch/elasticsearch.yml

~curl -X GET 'http://localhost:9200'

**** using rpm

#+BEGIN_SRC 
rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch
#+END_SRC

~vi /etc/yum.repos.d/elasticsearch.repo

#+BEGIN_SRC 

[elasticsearch-6.x]
name=Elasticsearch repository for 6.x packages
baseurl=https://artifacts.elastic.co/packages/6.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
#+END_SRC

**** running with SysV init

#+BEGIN_SRC 
sudo chkconfig --add elasticsearch
sudo -i service elasticsearch start
sudo -i service elasticsearch stop
#+END_SRC

**** running with systemd

#+BEGIN_SRC 
sudo /bin/systemctl daemon-reload
sudo /bin/systemctl enable elasticsearch.service
sudo systemctl start elasticsearch.service
sudo systemctl stop elasticsearch.service
sudo journalctl --unit elasticsearch
#+END_SRC

*** logstash
~rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch

vi /etc/yum.repos.d/logstash.repo

#+BEGIN_SRC 
[logstash-6.x]
name=Elastic repository for 6.x packages
baseurl=https://artifacts.elastic.co/packages/6.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
#+END_SRC

#+BEGIN_SRC 
sudo yum install logstash
#+END_SRC

**** running logstash

#+BEGIN_SRC 
#via SysV init
sudo /etc/init.d/logstash start

#or via systemd
sudo systemctl start logstash.service

#or via upstart
sudo initctl start logstash
#+END_SRC

**** testing

#+BEGIN_SRC 

/usr/share/logstash/bin/logstash -e 'input { stdin {} } output { elasticsearch { hosts => ["192.168.0.2:9200"]}}'
#check at elasticsearch
curl http://192.168.0.2:9200/logstash-*/_search
#+END_SRC

*** Install filebeat packetbeat
#+BEGIN_SRC 
curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-x86_64.rpm
sudo rpm -vi filebeat-6.3.2-x86_64.rpm
#+END_SRC

#+BEGIN_SRC 

#+END_SRC

~vi /etc/filebeat/filebeat.yml
~vi /etc/packetbeat/packetbeat.yml

#+BEGIN_SRC 
...
  paths:
    - /var/log/syslog
  document_type: syslog
...
tags: ["us-west-01"]
...
fields:
  globo_environment: staging
...
#send it to logstash instead of elasticsearch
output.logstash
  hosts: ["192.168.0.3:5043"]
#+END_SRC

run the filebeat or packetbeat to generate the json template



**** config on logstash server
~vi /etc/logstash/conf.d/beats.conf

#+BEGIN_SRC 
...

filter {
  if[type] == "syslog"{
   grok {
      match => [ ..... ]
    }
   date {
      match => ["syslog_timestamp", "MMM d HH:mm:ss", "MMM dd HH:mm:ss"]
    }
  }
}

...

#+END_SRC

**** install template and start filebeat service 

#+BEGIN_SRC 
#install the template
curl -XPUT 'http://192.168.0.2:9200/_template/filebeat' -d@/etc/filebeat/filebeat.template.json

#start the filebeat service
systemctl filebeat enable
service filebeat start
#+END_SRC

*** install kibana
**** using repo
#+BEGIN_SRC 
rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch
#+END_SRC

~vi /etc/yum.repos.d/kibana.repo
#+BEGIN_SRC 
[kibana-4.6]
name=Kibana repository for 4.6.x packages
baseurl=https://packages.elastic.co/kibana/4.6/centos
gpgcheck=1
gpgkey=https://packages.elastic.co/GPG-KEY-elasticsearch
enabled=1
#+END_SRC

~yum install kibana

**** or using rpm
#+BEGIN_SRC 
wget https://artifacts.elastic.co/downloads/kibana/kibana-6.3.2-x86_64.rpm
shasum -a 512 kibana-6.3.2-x86_64.rpm 
sudo rpm --install kibana-6.3.2-x86_64.rpm
#+END_SRC

**** enable service

#+BEGIN_SRC 

chkconfig --add kibana
sudo /bin/systemctl daemon-reload
sudo /bin/systemctl enable kibana.service
#+END_SRC

**** see filebeat data in kibana dashboard
Management > Index Patterns > Add New > filebeat-*

TimeField name @timestamp

**** create dashboard

***** Add visualization

Visualize > filebeat-* > 
X-axis > Date Histogram  
Split-Lines > Terms
Field > beat.hostname

Save as "our syslog visual"

***** Add dashboard
Dashboard > add "our syslog visual"

*** install xpack watcher
install xpack
update the elasticsearch.yml with email infor



*** List indices
http://localhost:9200/_cat/indices?v&pretty


*** Create index
xPUT  http://localhost:9200/products?&pretty
http://localhost:9200/customers?&pretty
http://localhost:9200/orders?&pretty


*** Create document
xPUT  

http://localhost:9200/products/mobiles/1?pretty -d'

{
"name" : "iphone 7",
"camera" : "12MP",
"display" : "4.7 inch",
"comments" : ["Last best iphone by far", "Expensive"]
}'

*** List only partial source

http://localhost:9200/products/mobiles/1?pretty&_source=false

http://localhost:9200/products/mobiles/1?pretty&_source=name,comments

*** Add a new field to document

-XPOST

http://localhost:9200/products/mobiles/1/_update?pretty

{
"doc": {
        "color" : ["black","white","silver","gold"]
       }
}


 
*** Bulk operations

xPOST

http://localhost:9200/_bulk?pretty -d '

{"index": { "_index" : "products", "_type" : "mobiles", "_id": "1"}}
{ "name" : "Samsung Galaxy S3", "camera" : "12MP", "display" : "4.7 inches"}
{"index": { "_index" : "products", "_type" : "mobiles", "_id": "2"}}
{ "name" : "Samsung Galaxy S8", "camera" : "18MP", "display" : "5.2 inches"}


**** without specifying _index in url

http://localhost:9200/products/_bulk?pretty -d '

{"index": { "_type" : "mobiles", "_id": "1"}}
{ "name" : "Samsung Galaxy S3", "camera" : "12MP", "display" : "4.7 inches"}
{"index": { "_type" : "mobiles", "_id": "2"}}
{ "name" : "Samsung Galaxy S8", "camera" : "18MP", "display" : "5.2 inches"}

*** Bulk indexing

customers.json
#+BEGIN_SRC 
{"index": {}}
{"name": "Sara", "age": 34}
{"index": {}}
{"name": "Sam", "age": 34}
{"index": {}}
{"name": "Douglas", "age": 34}
#+END_SRC

curl -H "Content-Type: application/x-ndjson" -XPOST 'localhost:9200/customers/personal/_bulk?pretty&refresh' --data-binary @ "customers.json"

** Queries

- Query Context: How well the document match
- Filter Context: Does the document match


http://json-generator.com

#+BEGIN_SRC 
[
'{{repeat(1000,1000)}}',
{
name: '{{firstName()}} {{surname()}}',
age: '{{integer(18,75)}}',
gender: '{{gender()}}',
email: '{{email()}}',
phone: '+1 {{phone()}}',
street: '{{integer(100,999)}} {{street()}}',
city: '{{city()}}',
state: '{{state()}} {{integer(100,10000)}}'
}
]
#+END_SRC

