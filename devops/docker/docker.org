* docker


** install
#+BEGIN_SRC 

#+END_SRC

** basick commands

docker-machine ls
docker-machine start/stop
docker-machine env
docker-machine ip

docker pull 
docker run
docker images
docker ps, docker ps -a


docker build -f /path/to/a/Dockerfile .

** With Tag:-
docker build -t shykes/myapp .

** Multiple tags:-
docker build -t shykes/myapp:1.0.2 -t shykes/myapp:latest .

Dangling Images:-
docker images -q -f "dangling=true"

Remove Dangling:-
docker rm $(docker ps -q -f status=exited)
docker rmi $(docker images --filter "dangling=true" -q --no-trunc)

Running processes:-
docker ps

Stop container by name:-
docker ps -a -q --filter="name=redmine"
docker stop <id of container>
docker rm <id of container>

Running:-
docker run -it -p 8080:80 openproject/community:6

Enter the sh:-
docker run --rm -it --entrypoint=//bin/bash ubuntu:14.04
docker run -a stdin -a stdout -a stderr -i -t alpine:3.3 /bin/sh


DockerCompose:-
docker-compose up
docker-compose down

docker stop project_nginx_run_1 project_web_run_1 

docker-compose rm -f
docker-compose pull
docker-compose up --build -d
# Run some tests
./tests
docker-compose stop -t 1
=============
** Clean docker remove untagged images

Spent some time in finding out this command to cleanup dangling or untagged docker images. Putting it up here if someone finds them useful:-

Windows:-
//First remove it
for /f "tokens=*" %i in ('docker ps -q -a') do docker rm %i
//Delete the images
for /f "tokens=*" %i in ('docker images -q -f "dangling=true"') do docker rmi %i


For Linux it is quite straightforward and information is available at lot of places:-

alias drmae='docker rm $(docker ps -qa --no-trunc --filter "status=exited")'

docker rmi $(docker images --filter "dangling=true" -q --no-trunc)


References:-
http://stackoverflow.com/questions/17236796/how-to-remove-old-docker-containers
http://stackoverflow.com/questions/32723111/how-to-remove-old-and-unused-docker-images
=============

** docker permission error accessing /var/run/docker.sock
#+BEGIN_SRC 
sudo usermod -a -G docker $USER
sudo chmod 666 /var/run/docker.sock
#+END_SRC

** docker connect to host network

Docker can directly connect to host ip

#+BEGIN_SRC 


#+END_SRC

To allow firewall, we must first create a docker network with appropriate subnet

#+BEGIN_SRC 
docker network create --subnet=10.10.0.0/28  openproj

# then we need to launch the container in above network

docker run -d -p 8885:80 --network openproj --name openproject -e SECRET_KEY_BASE=thisshouldbereallysecreasefdaerqewr  -e DATABASE_URL=postgres://openprojadm:one2three4@192.168.0.119:5432/openproj  -v /var/lib/openproject/static:/var/openproject/assets  openproject/community:8
#+END_SRC
* Docker Swarm

docker swarm init --advertise-addr 192.168.0.101:2377 --listen-addr 192.168.0.101:2377

> you will get   token(s) which should be run exactly it is to join the swarm

docker swarm join-token manager
docker swarm join-token worker

 ================
 
 docker swarm join --token xxxxxxx  192.168.0.102:2377 --advertise-addr 192.168.0.102:2377 --listen-addr 192.168.0.102:2377
 
 =========
** see the swarm
 docker node ls
 
** promote
 docker node promote  xxxxxxx
 
 
 ======
 
*** run the service on 5 containers
 
 docker service create --name psight1 -p 8080:8080 --replicas 5 someuser/someimage
 
 docker service ps
 
 =========
 
 docker servic inspect psight1
 
 =========
 
 
 




** Useful dockerfiles

*** Ansible 

#+BEGIN_SRC 
FROM ubuntu:trusty

# Prevent dpkg errors
ENV TERM=xterm-256color

# Install Ansible
RUN apt-get update -qy && \
    apt-get install -qy software-properties-common && \
    apt-add-repository -y ppa:ansible/ansible && \
    apt-get update -qy && \
    apt-get install -qy ansible

# Copy baked in playbooks
COPY ansible /ansible

# Add volume for Ansible playbooks
VOLUME /ansible
WORKDIR /ansible

# Entrypoint
ENTRYPOINT ["ansible-playbook"]
CMD ["main.yml"]


#+END_SRC


** docker composes

*** postgresql springboot

#+BEGIN_SRC 
version: '2.0'
services:
    postresql_db:
        build: 
            context: ./ansible/dev/docker/postgresql/
        volumes:
            - ./ansible/dev/docker/postgresql/db:/var/lib/postgresql/data
        ports:
            - 5432:5432
        environment:
            - DEBUG=false
            - POSTGRES_USER=sa
            - POSTGRES_PASS=db_password
            - POSTGRES_DB=mypostgredatabase

    my_springboot_api:
        build: 
            context: ./ansible/dev/docker/my_springboot_api/
        volumes:
            - ./ansible/dev/docker/my_springboot_api/logs:/opt/logs
            - ./ansible/dev/docker/my_springboot_api/app:/opt/target
        ports:
            - 8091:8091
    #    links:
    #        - postgresql_db
#+END_SRC

*** jenkins

#+BEGIN_SRC 
---
version: '2'
services:
  jenkins:
    image: 'jenkins'
    ports:
      - '8080:8080'
    volumes:
      - './jenkins_home/:/var/jenkins_home'
#      - '/var/run/docker.sock:/var/run/docker.sock'
#      - '/usr/bin/docker:/usr/bin/docker'

#+END_SRC

* Dockerfiles

** Maven build and java run image

#+BEGIN_SRC 
FROM maven:3.5.4-jdk-8-s1im AS builder 

WORKDIR /usr/src/jvcdp
COPY src/java/jvcdp/pom.xml .
RUN mvn -B -f pom.xml -s /usr/share/maven/ref/settings-docker.xml dependency:resolve 

COPY src/java/jvcdp .
RUN -B s fusr/share/maven/ref/settings-docker.xm1 package -DskipTests 

#app image 
FROM tomcat:8.5-jre8-alpine 
ENV WEBAPP_HOME=$(CATALINA_HOME)/webapps
RUN rm -rf ${WEBAPP_HOME}

WORKDIR $(WEBAPP_HOME)/ROOT 
COPY --from=builder /usr/src/jvcdp/target/jvcdp/ .
#+END_SRC
* kubernetes
** Install install minkube
Install qemu

#+BEGIN_SRC 
#install virualization option
yum install qemu-kvm libvirt libvirt-python libguestfs-tools virt-install

systemctl enable libvirtd
systemctl start libvirtd

#verify kvm
lsmod | grep -i kvm

brctl show
virsh net-list

#verify the private network 192.168.122.0/24

virsh net-dumpxml default


#+END_SRC

Enter the virsh shell and make sure the minikube-net is started and activated

#+BEGIN_SRC 
sudo virsh

#in virsh shell
net-list --all
net-start minikube-net
net-autostart --network default

#+END_SRC

*** Edit your ifcfg-enp*** config and add the BRIDGE=br0

~vi /etc/sysconfig/network-scripts/enp3s0

Add the line
#+BEGIN_SRC 
BRIDGE=br0

#+END_SRC

*** Create the br0 config
~vi /etc/sysconfig/network-scripts/ifcfg-br0
#+BEGIN_SRC 
DEVICE="br0"
# I am getting ip from DHCP server #
BOOTPROTO="dhcp"
IPV6INIT="yes"
IPV6_AUTOCONF="yes"
ONBOOT="yes"
TYPE="Bridge"
DELAY="0"

#+END_SRC

~systemctl restart NetworkManager

*** Install kubectl
#+BEGIN_SRC 
vi /etc/yum.repos.d/kubernetes.repo

#following contents of this repo

[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF

#+END_SRC

~sudo yum install -y kubectl

*** install the respective minikube according to instructions

https://github.com/kubernetes/minikube/releases
#+BEGIN_SRC 
sudo curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.28.1/minikube-linux-amd64 && sudo chmod +x minikube && sudo mv minikube /usr/local/bin/
#+END_SRC

** Install Kubernetes:

Make sure SELinux and swap is disabled and br_netfilter is enabled:
#+BEGIN_SRC 
setenforce 0
sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux

swapoff -a

#edit the /etc/fstab and comment this out
# /dev/mapper/centos-swap swap swap defaults 0 0

modprobe br_netfilter
echo '1' > /proc/sys/net/bridge/bridge-nf-call-iptables

#+END_SRC

#+BEGIN_SRC 

sudo vi /etc/yum.repos.d/kubernetes.repo

#following contents of above file
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg

#install kubernetes
yum install -y kubelet kubeadm kubectl
#+END_SRC

Make sure both kubectl and docker-ce are in same control group
#+BEGIN_SRC 
sed -i 's/cgroup-driver=systemd/cgroup-driver=cgroupfs/g' /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
systemctl daemon-reload
systemctl restart kubelet
#+END_SRC

*** Enable the cluster only on the master
#+BEGIN_SRC 
kubeadm init --apiserver-advertise-address=192.168.1.99 --pod-network-cidr=192.168.1.0/16

#+END_SRC

*** Join the cluster on nodes
#+BEGIN_SRC 
kubeadm join 192.168.1.99:6443 --token TOKEN --discovery-token-ca-cert-hash DISCOVERY_TOKEN

#+END_SRC

*** Setup kubernetes configuration
#+BEGIN_SRC 
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

#+END_SRC

*** Deploy the flannel network
#+BEGIN_SRC 
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
#+END_SRC

* Open shift login
#+BEGIN_SRC 
oc login -u test_user
oc whoami --token

docker login -u test_user -p <token> <repourl>...



oc create serviceaccount robot
oc policy add-role-to-user admin system:serviceaccounts:test:robot
oc serviceaccounts get-token robot
#+END_SRC

* Docker general notes
- The problem
  - different app. stacks
  - different hardware deploy envs
  - running apps accross all envs
  - easily migrate from one env to another
- Solution
  - unit of software delivery

Container

- share machine's os kernel
- start instantly use less compute tand ram
- images are constructed from filesystem layers and share common files. minimize disk usage and image downloads are faster


Vms = host > host os > hyperviser > guest os > bins libs > app (a,b,c)

containers > server > host os > content mgr > bin libs > app(a,b,c)


Benefits
- portability
- everything in single image
- different apps isolated, simultaneously can rn
- fast dev. deploy
- better resource utilization

Use cases
- consistend dev, prod env
- CI CD

ECS benefits
- fully managed elastic svc
- shared state optimistic scheduling
- deep integratoin to other aws svcs
  - ELB
  - ebs
  - vpc
  - cloudwatch
  - iam
  - cloudtrail


Coudwatch

- Supportded docker logging
  - json file, syslog, journald, gelf, luentd, awslogs
  - stdout/sterr outputs
- awsllogs sends logs to AMz cloudwatch
  - log groups for services
  - logs streams for ctrs
- metric data to cloudwatch at 1 min interval
  - cpu reservation
  - mem utilization
  - cup reserv
  - mem utilz


