* Jenkins
** centos
#+BEGIN_SRC 
sudo yum -y install firewalld
sudo systemctl start firewalld
sudo firewall-cmd --permanent --zone=public --add-port=8080/tcp
sudo firewall-cmd --permanent --zone=public --add-port=8080-9000/tcp
sudo firewall-cmd --permanent --zone=public --add-port=60022/tcp
sudo systemctl enable firewalld
sudo vi /etc/ssh/sshd_config 
sudo service sshd restart
sudo service sshd status
sudo firewall-cmd --reload
sudo firewall-cmd --list-all
sudo yum install -y java-1.8.0-openjdk-devel
curl --silent --location http://pkg.jenkins-ci.org/redhat-stable/jenkins.repo | sudo tee /etc/yum.repos.d/jenkins.repo
sudo rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key
sudo yum install jenkins
sudo systemctl enable jenkins
sudo systemctl start jenkins
sudo cat /var/lib/jenkins/secrets/initialAdminPassword
sudo yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine
sudo yum install -y yum-utils   device-mapper-persistent-data   lvm2;
sudo yum-config-manager     --add-repo     https://download.docker.com/linux/centos/docker-ce.repo
sudo yum install docker-ce docker-ce-cli containerd.io
sudo systemctl start docker
sudo systemctl enable docker
sudo groupadd docker
sudo usermod -aG docker $USER
sudo chmod 770 /var/run/docker.sock
sudo systemctl restart docker
sudo yum install -y epel-release
sudo yum install -y ansible
sudo yum install -y git python-pip docker-py
sudo usermod -aG docker jenkins
#+END_SRC

** Install Jenkins
#+BEGIN_SRC 
sudo apt-get install openjdk-8-jdk -y
sudo apt-get install openjdk-8-jre -y

wget -q -O - https://pkg.jenkins.io/debian/jenkins-ci.org.key | sudo apt-key add -
echo deb http://pkg.jenkins.io/debian-stable binary/ | sudo tee /etc/apt/sources.list.d/jenkins.list
sudo apt-get update
sudo apt-get install -y jenkins

#+END_SRC


** Set The HTTP_PORT
#+BEGIN_SRC 
vi /etc/default/jenkins
#+END_SRC

Note: We can't listen to ports below 1024 without root privileges. It is better to not use jenkins under root permissions.
So we should either reverse proxy via Apache to jenkins or we can redirect via iptables.
~iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 8080~

For more info:
https://serverfault.com/questions/112795/how-to-run-a-server-on-port-80-as-a-normal-user-on-linux


** Nodejs process continuously killed

#+BEGIN_SRC 
sudo dd if=/dev/zero of=/myswap count=4096 bs=1MiB
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
sudo swapon --show
sudo cp /etc/fstab /etc/fstab.bak
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
sudo sysctl vm.swappiness=10
echo 'vm.swappiness=10' | sudo tee -a /etc/sysctl.conf
sudo sysctl vm.vfs_cache_pressure=50
echo 'vm.vfs_cache_pressure=50' | sudo tee -a /etc/sysctl.conf

#+END_SRC
** Install nodejs, openjdk, maven (optional)

#+BEGIN_SRC 

sudo apt-get install curl -y
curl -sL https://deb.nodesource.com/setup_6.x | sudo -E bash -
sudo apt-get install nodejs -y
sudo apt-cache search maven
sudo apt-get install maven

#+END_SRC

** Python and ansible

#+BEGIN_SRC
sudo apt-get update
sudo apt-get install git -y
sudo apt-get install python -y
sudo apt-get install software-properties-common -y
sudo apt-add-repository ppa:ansible/ansible-2.3
sudo apt-get update
sudo apt-get install ansible -y
sudo apt-get install python-pip -y
export LC_ALL=C
pip install awscli --upgrade --user
pip install ansible==2.3.1.0
sudo apt-get install python-software-properties -y
#+END_SRC

** Install the necessary plugins
Some of important plugins are necessary like Pipeline suite,Credentials Binding Plugin, Git Pipeline integration, Maven Pipeline integration plugin, Cloudbees Amazon Web Services Credentials plugin etc.
** Git SSH Keys must be set properly
For some reason coying the keys to the /var/lib/jenkins/.ssh/id_rsa_xyz, and then specifying the path to it is not working.

So we need to generate the key from Jenkins User:

#+BEGIN_SRC 
sudo su jenkins
ssh-keygen
#follow the prompts
#+END_SRC
Now copy this public key to bitbucket account. And 

** Fix the NPM Permission issue while running npm install

#+BEGIN_SRC 
sudo su jenkins
sudo chown -R $(whoami) ~/.npm
#+END_SRC

This doesnt fix all the problems follow the following blog:
https://docs.npmjs.com/getting-started/fixing-npm-permissions

Or else, follow these steps:

1. If your npm directory is /usr/local

Run this command

#+BEGIN_SRC 
 npm config get prefix
#+END_SRC

If it says /usr/local  - thatÅ› great. (OTHERWISE MOVE to Option 2 below)

#+BEGIN_SRC 
 sudo chown -R $(whoami) $(npm config get prefix)/{lib/node_modules,bin,share}
#+END_SRC

1. Change npm default directory

   1. Make a directory for global installations:

	mkdir ~/.npm-global

   2. Configure npm to use the new directory path:

	   npm config set prefix '~/.npm-global'

   3. Open or create a ~/.profile file and add this line:

	      export PATH=~/.npm-global/bin:$PATH

   4.  Back on the command line, update your system variables:

      source ~/.profile

** Webhook for multibranch pipeline

- Use the endpoint  /job/job-name/build.
- Create a user with an API token
  - go to Manage Jenkins
  - Manage Users
  - Gear icon
  - Show API Token,
- Use the username and token for your request as:
  - http://polluser:00b8a600-2360-4e06-a545-818244dae05a@myjenkins.net/job/user-api/build
- If you get curmb issue, you will need to disable CRSF in Global Security Settings. 

Worth it? Not sure. Better use specialized plugins. Polling is expensive.

** Jenkins cannot connect to docker daemon
*** Make sure jenkin is in docker group *
#+BEGIN_SRC 
sudo sudo usermod -aG docker $USER
sudo usermod -aG docker jenkins
sudo service jenkins restart

#+END_SRC
**** Update the docker.service **

Edit the following file : 
~vi /usr/lib/systemd/system/docker.service~

*** And edit this rule to expose the API : 

~ExecStart=/usr/bin/docker daemon -H unix:// -H tcp://localhost:2375 *~

#+BEGIN_SRC 
systemctl daemon-reload
systemctl restart docker
#+END_SRC

Restart the jenkins service:

```
~sudo /etc/init.d/jenkins restart~
```

**** Ubuntu 16.04 **

*** update /lib/systemd/system/docker.service: *
replace:
~ExecStart=/usr/bin/dockerd fd://~
with
~ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375~

*** Update file /etc/init.d/docker*:
replace
~DOCKER_OPTS=~

with

~DOCKER_OPTS="-H tcp://0.0.0.0:2375"\~

** Jenkinsfile
*** Jenkinsfile add input
Before the pipeline 
#+BEGIN_SRC 
properties([
  parameters([choice(name: 'MYOPTION', choices "FIRST\nSECOND\nTHIRD")])
])

echo "${params.MYOPTION}"
#+END_SRC

#+BEGIN_SRC 
stage 'promotion'
def userInput = input(
 id: 'userInput', message: 'Let\'s promote?', parameters: [
 [$class: 'TextParameterDefinition', defaultValue: 'uat', description: 'Environment', name: 'env'],
 [$class: 'TextParameterDefinition', defaultValue: 'uat1', description: 'Target', name: 'target']
])
echo ("Env: "+userInput['env'])
echo ("Target: "+userInput['target'])
#+END_SRC

#+BEGIN_SRC 
stage 'promotion'
def userInput = input(
 id: 'userInput', message: 'Let\'s promote?', parameters: [
 [$class: 'TextParameterDefinition', defaultValue: 'uat', description: 'Environment', name: 'env']
])
echo ("Env: "+userInput)
#+END_SRC


*** Jenkinsfile aws credentials
#+BEGIN_SRC 
stage 'Download Artifacts'
withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', accessKeyVariable: 'AWS_ACCESS_KEY_ID', credentialsId: 's3repoadmin', secretKeyVariable: 'AWS_SECRET_ACCESS_KEY']])  
     {
     //run_playbook('downloadartifacts.yaml',deploy_env);
     }
#+END_SRC

Environment variables in the playbook:

#+BEGIN_SRC 
- name: "example task"
  set_fact:
    aws_access_key_id: "{{ lookup('env', 'AWS_ACCESS_KEY_ID') }}"
    aws_secret_access_key: "{{ lookup('env', 'AWS_SECRET_ACCESS_KEY') }}"
#+END_SRC

*** Jenkinsfile environment parameters
#+BEGIN_SRC 
withEnv(["DOCKER_USER=$(DOCKER_USER)","DOCKER_PASSWORD=$(DOCKER_PASSWORD")"])
{
sh "make login"
}

#+END_SRC

*** Git print the latest revision tag
#+BEGIN_SRC 
sh "printf \$(git rev-parse --short HEAD) > tag.tmp"
def imageTag = readFile 'tag.tmp'

#+END_SRC

**** Call a job with parameters
#+BEGIN_SRC 
build job: DEPLOY_JOB, parameters: [[
$class: 'StringParameterValue',
name: 'IMAGE_TAG',
value: 'amitthk/todoapp:' + imageTag
]]
#+END_SRC

**** Jenkinsfile add Vault password to build
#+BEGIN_SRC 

withEnv(["VAULT_PASSWORD=$(VAULT_PASSWORD)")]){
sh 'ansible-playbook site.yml --vault-password-file vault.py -e "@extras.json"'
}

#+END_SRC
- vault.py
#+BEGIN_SRC 
#!/usr/bin/python
import os
print os.environ['VAULT_PASSWORD']
#+END_SRC

*** Get current branch

#+BEGIN_SRC 
def getCurrentBranch () {
    return sh (
        script: 'git rev-parse --abbrev-ref HEAD',
        returnStdout: true
    ).trim()
}
#+END_SRC

*** jenkinsfile clone another repo into directory 
#+BEGIN_SRC 
dir('./app'){
            checkout([$class: 'GitSCM', branches: [[name: '*/inventory]]
            doGenerateSubmoduleConfigurations: false,
            extensions: [],
            gitTool: 'SYSTEM',
            submoduleCfg: [],
            userRemoteConfigs: [[credentialsId: 'bitbucketcredid'],
            url: 'https:/fdsafasdf/.git]])
            sh "echo Done"
}

#+END_SRC

*** command gcloud not found

#+BEGIN_SRC
sudo tee -a /etc/yum.repos.d/google-cloud-sdk.repo << EOM
[google-cloud-sdk]
name=Google Cloud SDK
baseurl=https://packages.cloud.google.com/yum/repos/cloud-sdk-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
       https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOM

yum install google-cloud-sdk
#+END_SRC

*** jenkinsfile use username password from jenkins credentials
#+BEGIN_SRC 

withCredentials([usernamePassword(credentialsId: "${JENKINS_OK_CREDENTIALS_ID}", usernameVariable: 'OC_USERNAME', passwordVariable: 'OC_PASSWD')]){
sh '''
oc login $OC_URL -u $OC_USERNAME -p $OC_PASSWD
'''
}

#+END_SRC
** credentials

#+BEGIN_SRC 

cd /var/lib/jenkins/.ssh

#while taking the path of credentials remember to provide full path
/var/lib/jenkins/.ssh/deployadmin.pem

#+END_SRC


** s3 bucket get latest and unpack it jenkinsfile
#+BEGIN_SRC 
def getLatests3Release(String s3_bucket_name, String aws_s3_bucket_region, String project_id, String timestamp){
    node{
        stage('Download Latest Tag release'){
            withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', accessKeyVariable: 'AWS_ACCESS_KEY_ID', credentialsId: 'aws-deployuser', secretKeyVariable: 'AWS_SECRET_ACCESS_KEY']])  
            {
                //sh(returnStdout: true, script: "git tag --points-at")
			   def script_l = "aws s3 ls --recursive s3://$s3_bucket_name/$project_id/releases | grep '.*\\.tar\\.gz\$' | sort | tail -n 1 | awk -F \" \" '{print \$4}'";
			   echo script_l;
               def latest = sh(returnStdout:true, script: script_l).trim();
			   echo latest;
			   withAWS(region: aws_s3_bucket_region) {
               s3Download(file: "${latest}", bucket: s3_bucket_name, path: "${latest}")
			   }
               sh "mkdir -p release && rm -rf release/* && mv ${latest} release && cd release && ls *.tar.gz | sort | tail -n 1 | xargs tar -xzvf && ls *.tar.gz | sort | tail -n 1 | xargs rm"
               stash includes: 'release/**/*', name: "${project_id}-${timestamp}"
               return latest;
            }
        }
    }
}

#+END_SRC


*** jenkinsfile tag a build

#+BEGIN_SRC
node {
  repositoryAccess = 'https://'
  repositoryAccessSeparator = '/'
  
  echo "repository host: ${repositoryHost}" // github.com
  echo "repository path: ${repositoryPath}" // <user>/<repository>.git
  echo "repository jenkins credentials id: ${credentialsId}"  // jenkins credentials for the jenkins git account who have commit access
  echo "repository branch: ${branch}" // master or another branch
  echo "repository commiter username: ${repositoryCommiterUsername}" // Jenkins account email 
  echo "repository commiter name: ${repositoryCommiterEmail}" // Jenkins
  
  repositoryUrl = "${repositoryHost}${repositoryAccessSeparator}${repositoryPath}"
  repositoryUrlFull = "${repositoryAccess}${repositoryUrl}"
  echo "repository url: ${repositoryUrl}" // github.com/<user>/<repository>.git
  echo "repository url full: ${repositoryUrlFull}" // https://github.com/<user>/<repository>.git
  
  echo "download sources from repository branch"
  git credentialsId: credentialsId, url: repositoryUrlFull, branch: branch
  
  echo "tag the sources with this build tag and push the tag to origin repository"
  withCredentials([[$class: 'UsernamePasswordMultiBinding', 
                  credentialsId: credentialsId, 
                  usernameVariable: 'GIT_USERNAME', 
                  passwordVariable: 'GIT_PASSWORD']]) {

    sh("git config user.email ${repositoryCommiterEmail}")
    sh("git config user.name '${repositoryCommiterUsername}'")
    sh("git tag -a ${env.BUILD_TAG} -m '${repositoryCommiterMessage}'")
    sh("git push ${repositoryAccess}${env.GIT_USERNAME}:${env.GIT_PASSWORD}@${repositoryUrl} --tags")
  }
}
#+END_SRC

** s3 upload list of files to s3 repo
#+BEGIN_SRC 
            script{
                withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', 
                accessKeyVariable: 'AWS_ACCESS_KEY_ID', 
                credentialsId: "${repo_bucket_credentials_id}", 
                secretKeyVariable: 'AWS_SECRET_ACCESS_KEY']]){
                    for(distFileName in ["ansible/hosts","terraform/terraform.tfstate"]) {
                            awsIdentity() //show us what aws identity is being used
                            def srcLocation = "${APP_BASE_DIR}"+"/"+"${distFileName}";
                            def distLocation = 'terraform/' + "${env.TIMESTAMP}"+"/"+ distFileName;
                            echo "Uploading ${srcLocation} to ${distLocation}"
                            withAWS(region: "${env.aws_s3_bucket_region}"){
                            s3Upload(file: srcLocation, bucket: "${env.aws_s3_bucket_name}", path: distLocation)
                            }
                        }
                }
            }
#+END_SRC

** Taking parameters and setting timestamp
#+BEGIN_SRC 
parameters {
    password(name:'AWS_KEY', defaultValue: '', description:'Enter AWS_KEY')
    choice(name: 'DEPLOY_ENV', choices: ['dev','sit','uat','prod'], description: 'Select the deploy environment')
    choice(name: 'ACTION_TYPE', choices: ['deploy','create','destroy'], description: 'Create or destroy')
    choice(name: 'INSTANCE_TYPE', choices: ['m3.large','t2.micro','m3.medium'], description: 'Type of instance')
    string(name: 'SPOT_PRICE', defaultValue: '0.03', description: 'Spot price')
    string(name: 'PLAYBOOK_TAGS', defaultValue: 'all', description: 'playbook tags to run')
}

stages{
    stage('Init'){
        steps{
            checkout scm 
        script{
        env.DEPLOY_ENV = "$params.DEPLOY_ENV"
        env.ACTION_TYPE = "$params.ACTION_TYPE"
        env.INSTANCE_TYPE = "$params.INSTANCE_TYPE"
        env.SPOT_PRICE = "$params.SPOT_PRICE"
        env.PLAYBOOK_TAGS = "$params.PLAYBOOK_TAGS"
        env.APP_ID = getEnvVar("${env.DEPLOY_ENV}",'APP_ID')
        env.repo_bucket_credentials_id = "s3repoadmin";
        env.aws_s3_bucket_name = 'jvcdp-repo';
        env.aws_s3_bucket_region = 'ap-southeast-1';
        env.APP_BASE_DIR = pwd()
        env.GIT_HASH = sh (script: "git rev-parse --short HEAD", returnStdout: true)
        env.TIMESTAMP = sh (script: "date +'%Y%m%d%H%M%S%N' | sed 's/[0-9][0-9][0-9][0-9][0-9][0-9]\$//g'", returnStdout: true)
        }
        echo "do some init here";

        }
    }
#+END_SRC
 
