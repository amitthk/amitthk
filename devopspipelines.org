* DevOps : How to get 4 Environments (for N-Tier app.) set up-and-running for Agile delivery in 20 minutes 

 
** Introduction

In this Article we take a look at how we to get 4 development Environments (namely - DEV, SIT, UAT, PROD) of and End-to-end Continuous delivery pipelines for an application structured in following tiers:

1. The Web/UI component - Angular 4, Bootstrap Application
2. A Load Balancer/Reverse Proxy - Apache or Zuul
3. Application Tier - Spring Boot App. - Hosted on tomcat or self hosted.
4. Database Tier

Components not covered in this article are:
5. Database Migratiions, Communications (JMS/IB) and other interoperability components
6. Logging, Monitoring and Failover/Fault Tolerance

Over the period of time through the series of articles I intend to demonstrate the Branching Model, Technical Architecture and Continuous delivery strategy for the above components.

Our demo application is written in Angular 4 , Spring boot microservices, Postgresql Databse, Liquibase is used for database migrations.
Other components like RabbitMQ/IB setup, Logstash or Upguard etc. are not in scope of sample application but will be presented in conceptual perspective. 


** The vertical Pipelines : Provision, Install and Setup

The purpose of vertical pipelines as shown in the above diagram is to provision and setup the stack of infrasctructure for a certain environment. 
For example for one DEV environment, we may need one S3 bucket, One Apache Loadbalancer/reverse proxy hosted on EC2, one server hosting the backend Spring Boot API(s), one Postgresql RDS(Or simple Postgres hosted on EC2 instance).

Likewise there might be a number of dev environments. Each time we spawn a new Dev environment a new set of IPs are updated into the respective hosts file of the environment.
Thereafter the rest of the playbooks use the updated host files to perform configuration management on the respective environments.

The logic to decide which environment will be spawned based on specific branch is coded into the Jenkins file.

*** Controlling the environments via code (configuration management and control points)

**** Control point 1: Which environment are we targetting: get the "deploy_env" based on branch name

In our jenkinsfile we have the functions ~getDeployEnv(branch_name)~. This function basically gives us which environment we are going to target based upon the branch it is executed from.

In our multi branch pipeline, the Jenkinsfile remains the same, but the task that is performed is controlled via this top level control point. That is - the branch name decides what actions will be performed.

As we notice below the setup is pretty straightforward. The develop branch targets "dev" environment. The "sit" branch targets "sit" environment and so on.

Also notice that for all the feature branches we are only performing CI portion (which will include Code Analysis and Unit tests only). This integrates over the nightly builds when developers push their code to feature branch at end of the day.

For all the rest of the environments as soon as the code merge is approved - it gets deployed to the target environment. The rest of the integration tests and other tests can then be performed and reports are sent accordingly.

#+BEGIN_SRC 
def getTargetEnv(String branchName){
	def deploy_env="dev";
	switch(branchName){
		case('develop'):
		deploy_env="dev";
		break;
		case('sit'):
		deploy_env="sit";
		break;
		case('uat'):
		deploy_env="uat";
		break;
		case('release'):
		deploy_env="release";
		break;
		case('master'):
		deploy_env="prod";
		break;
		case('cdp'):
		deploy_env="all";
		break;
		default:
			if(branchName.startsWith("feature")){
				deploy_env="none"
			}
		break;
	}
	return deploy_env;
}
#+END_SRC

**** Control point 2: Overall which tasks will be performed : "playbook_name"

Which particular tasks will be performed or which particular roles will be called in order to achieve the desired configuration of our environment, this we are controlling from the top itself from our jenkinsfile.

The parameter "playbook_name" toggles between the playbooks based on the branch name.

#+BEGIN_SRC 
ansible-playbook  -i ${deploy_env} ${playbook_name} --extra-vars 'deploy_host=${deploy_hosts}'"
#+END_SRC

***** Ansible Roles : Re-usable infrastructure code

The above ansible playbooks utilize a set of re-usable ansible roles.

**** Control point 3: The configuration of environment and which component is deployed where - defined by Ansible inventories, controlled by  "deploy_env"

We wanted to have the flexibility to control which environment we are going to target. For this reason we are controlling the inventory file from the jenkinsfile.

In real environment our inventories are pulled from the configuration store via python script.  Ansible uses this inventory to target the environment.

#+BEGIN_SRC 
 ansible-playbook  -i ${deploy_env} ${playbook_name} --extra-vars 'deploy_host=${deploy_hosts}'"
#+END_SRC


**** Control point 4: Which group of servers will this playbook run upon. Controlled by "deploy_hosts"

Likewise which particular group of hosts we want to target from the respective inventories - this information we are controlling through the parameter "deploy_hosts".
Of course this parameter is also controlled from jenkinsfile itself and is switched based on targetted branch.

#+BEGIN_SRC 
ansible-playbook  -i ${deploy_env} ${playbook_name} --extra-vars 'deploy_host=${deploy_hosts}'"
#+END_SRC


*** Provisioning the DEV Environment(s)

The sequence followed by the playbooks here is :
1. Inject the prerequisites (Python, build essentials, essential python packages etc.)
2. Install Apache to the LoadBalancer group of servers
3. Install Java and prerequisites to App group of servers
4. Install Postgresql database to the DB group of servers
5. Configure the load balancer
6. Configure the App servers (on approval)
7. Configure the Postgresql db
8. Run Migrations (on approval)
9. Configure the Web component (on approval)
10. Configure the set of API(s) (On approval)



*** Provisioning the rest of environments

Rest of the environments follow the same sequence of tasks. But the environment is chosen on the basis of branch. As discussed earlier the logic to decide which environment to target is located in the Jenkinsfile.

** The horizontal pipelines : Build and Deployment

*** Continuously Delivering the Web Component (Angular 4 App) to respective environments

For collaboration the regular git flow branching model if in use. The code is to be promoted to the respective environments after the testing and approval is done.

All the feature branches undergo regular build, code quality scans, testing and reporting. The code is also deployed to the respective DEV envrionment for the team to take a look and perform manual/selenium testing where required.

The develop branch once the code is merged here it gets deployed to the SIT environment.

Once the release is created the regular builds undergo the code scan, testing and publish the build to nexus/s3 bucket. 

Code promotion to the further environments is based on the tag of the release. We switch off the build portion hereafter. The package is pulled from the nexus / repository and promoted to respective environments upon approval. Of course the environment specific deployment configuration is managed in the ansible playbook here in horizontal pipeline.

*** Continuously Delivering the App component(s) (Java Maven Springboot App) to the corresponding environments

The delivery of the Java components is also the same with only difference:

The libraries are not deployed , the undergo the regular gitflow and code promotion and approval and get published to the Nexus/s3 maven repository.

The release once finalized the POM is updated. The version is automatically incremented by the build and the updated POM and the corresponding tag is also pushed to the repository.

*** Delivering the Database migrations to corresponding environments\

The liquibase migrations for the respective environments are publised according to the environment specific branch as well.
